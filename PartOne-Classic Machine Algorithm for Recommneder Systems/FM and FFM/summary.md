# 从FM到FFM——自动特征交叉的解决方案

# 零、动机

逻辑回归模型表达能力不强的问题，会不可避免地造成有效信息的损失。在仅使用单一特征而非交叉特征进行判断的情况下，有时不仅是信息损失的问题，甚至会得出错误的结论。

辛普森悖论：在对样本集合进行分组研究时，在分组比较中都占优势的一方，在总评中有时反而是失势的一方。

# 一、POLY2模型——特征交叉的开始

POLY2的数学模型如下：

![image](https://user-images.githubusercontent.com/93982957/147383650-a3840224-dc24-4951-beeb-5dc2dd7e2600.png)

该模型对所有特征进行了两两交叉，并对所有的特征赋予权重。POLY2通过暴力组合特征的方式，在一定程度上解决了特征组合的问题。POLY2模型本质上还是线性模型，其训练方法与逻辑回归并无区别，因此便于工程上的兼容。

缺点：

    1、在处理海量互联网数据时，经常使用one-hot编码的方法处理类别数据，致使特征向量极度稀疏，POLY2进行无选择的特征交叉，使得原本就非常稀疏的特征向量更加稀疏，导致大部分交叉特征的权重缺乏有效的数据进行训练，无法收敛。
    
    2、权重参数数量从n到n^2，训练开销增加。

# 二、FM模型——隐向量特征交叉

下式为FM二阶部分的数学形式，与POLY2模型相比，其主要区别是用两个向量的内积取代了单一的权重系数。具体地说，FM为每个特征学习了一个隐权重向量。在特征交叉时，使用两个特征隐向量的内积作为交叉特征的权重。

![image](https://user-images.githubusercontent.com/93982957/147383779-d6b937ce-740e-4b26-a8cf-7128134eeb45.png)

FM通过引入特征隐向量的方法，直接把POLY2模型n^2级别的权重参数数量减少到了nk(k为隐向量维度，n>>k)。在使用梯度下降法进行FM训练的过程中，FM的训练复杂度同样可被降低到nk级别，大大降低了训练开销。

隐向量的引入使FM能更好地解决数据稀疏性的问题，相比与POLY2，FM虽然丢失了某些具体特征组合的精确记忆能力，但是泛化能力大大增加。

# 三、FFM——引入特征域的概念

相比于FM模型，FFM模型引入了特征域感知这一概念，使模型的表达能力更强。

![image](https://user-images.githubusercontent.com/93982957/147383966-4f9acbd0-372a-47fa-9ca3-37d0ff7603f4.png)

该式为FFM的数学形式的二阶部分。其与FM的区别在于每个特征对应的不是唯一一个隐向量，而是一组隐向量。

优点：

    1、相较于FM，特征之间的学习更加合理。
    
    2、计算时间和效果都很好。
    
缺点：

    1、FFM模型的复杂度上升到了kn^2，计算开销大大增加。
    
    2、POLY2、FM、FFM对类别型特征的处理很好，对数值型特征的处理很差。
    
    
