# 一、GBDT模型

    集成学习是一种协同多个学习器完成任务的学习方法，其原理是使用某一种方式将多个学习器进行集成，以此获得比单一学习器更优的泛化性能。梯度提升决策树(GBDT)是一种Boost集成学习算法，其核心思想是通过多轮迭代产生多个弱分类器，在每一次迭代后计算损失函数的负梯度，将其作为残差的近似值。在GBDT分类模型中，一般使用CART回归树作为基学习器，每个分类学习器的训练都是基于上一轮分类器预测结果的残差，以串行的方式向残差减小的方向进行梯度迭代，最后将每个弱分类器得到的结果进行加权求和得到最终的分类器。

    GBDT是采用加法模型（基函数的线性组合），以及不断减小
    
