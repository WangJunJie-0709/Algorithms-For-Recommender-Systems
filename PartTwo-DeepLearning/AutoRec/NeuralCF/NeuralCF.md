# NeuralCF模型-CF与深度学习的结合

# 一、从深度学习的角度重新审视矩阵分解模型

Embedding层的主要作用是将稀疏向量转换成稠密向量，事实上，若从深度学习的视角看待矩阵分解模型，那么矩阵分解层的用户隐向量和物品隐向量完全可以看作一种Embedding方法。最终的"Scoring"层就是将用户隐向量和物品隐向量进行内积操作后得到"相似度"，这里的"相似度"就是对评分的预测。

但由于矩阵分解模型结构相对比较简单，尤其是"Scoring"层无法对优化目标进行有效的拟合，所以在实际使用矩阵分解来训练和评估模型的过程中，往往会发现模型容易处于欠拟合的状态。

# 二、NeuralCF模型的结构

![21550b3a1c500e0eb4e97b99d0a73a8](https://user-images.githubusercontent.com/93982957/146736064-94b2d044-9274-4ea5-9d57-cf8b73d11e6c.png)

如上图所示，NeuralCF用"多层神经网络+输出层"的结构替代了矩阵分解模型中简单的内积操作。这样做有两个好处：一是让用户向量和物品向量做更充分的交叉，得到更多有价值的特征组合信息。二是引入更多的非线性特征让模型的表达能力更强。

用户和物品向量的互操作层可以被任意的互操作形式所代替，这就是所谓的"广义矩阵分解"模型。

![4c4fe748243feaa91cbd2604d95fe48](https://user-images.githubusercontent.com/93982957/146736861-3e3c3817-d0d4-4858-9c27-59e16c09fc73.png)

NeuralCF混合模型整合了上面提出的原始NeuralCF模型和以元素积为互操作的广义矩阵分解模型。这让模型具有了更强的特征组合和非线性能力。

# 三、NeuralCF模型的优势和局限性

优势：

  1、Neural模型基于用户向量和物品向量这两个Embedding层，利用不同的互操作层进行特征的交叉组合，并且可以灵活地进行不同互操作层的拼接。
  
  2、利用神经网络理论上能够拟合任意函数的能力，灵活地组合不同的特征，按需增加或减少模型的复杂度
  
 局限性：
 
  1、由于是基于协同过滤的思想进行构造的，所以Neural模型并没有引入更多其他类型的特征，这在实际应用中无疑浪费了其他有价值的信息。
  
  2、对于模型中互操作的种类并没有做进一步的探究和说明。
